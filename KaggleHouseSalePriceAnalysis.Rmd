---
title: "MSDS 6371 Project"
author: "Halle Purdom & Taylor Bonar"
date: "4/11/2021"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#loading libraries
library(GGally)
library(ggthemes)
library(ggplot2)
library(ggResidpanel) # Residual Plots (e.g. resid_panel())
library(scales) # Scales used to correct some of the scaling on graphs
library(naniar)
library(tidyr)
library(tidyverse)
library(plyr)
library(dplyr)
library(caret)
library(class)
library(e1071)
library(tm)
library(plotly)
library(olsrr)
library(cowplot)
library(IDPmisc)
# HTML CSS - Libraries for Coefficient Table (e.g. tab_model())
library(sjPlot)
library(sjmisc)
library(sjlabelled)
# Cross-Validation Statistic CV() Library
library(forecast)

train = read.csv("./train.csv", header = TRUE)
test = read.csv("./test.csv", header = TRUE)

```

# Analysis 1: How does the Square Footage of the Living Area Affect Sale Prices for the Houses in North Ames, Edwards, and Brookside?

## Step 1: Building and Fitting Our Initial Model
Initial Model: $\hat{Sale Price} =  \hat{\beta_0} + \hat{\beta_1} (Living Area ft^2)$
```{r Initial Fit, echo=T}
# Filtering for desired neighborhoods into a separate dataframe
train_filtered = train %>% filter(Neighborhood == "NAmes" | Neighborhood == "Edwards" | Neighborhood == "BrkSide") %>% select(SalePrice, GrLivArea)

# Sales Prices' relation to square footage of the Living Area
## Create linear model of Response (SalePrice) to Explanatory Variables (GrLivArea)
fit_initial = lm(SalePrice~GrLivArea, data=train_filtered)
## Find the overall Summary and Confidence Interval of our Linear Model
# Option 1 for auto-generating summary statistics -- PDF doesn't like, good for HTML quick referencing
tab_model(fit_initial, show.se = T, show.stat = T, string.stat = "t-value", string.p = "p-value", string.se = "Std. Error", pred.labels = c("Intercept", "Sq. Ft. of Living Area"))
# Option 2 - Use for PDF
summary(fit_initial)
confint(fit_initial)
CV(fit_initial)
cor(train_filtered)

## Generate Linear Regression Line
preds = predict(fit_initial)
train_filtered %>% ggplot(aes(y = SalePrice, x = GrLivArea)) +
  geom_point() + geom_smooth(method = "lm", formula = y~x) +
  ggtitle("Linear Regression Model: Living Area vs. Sale Price", "For Houses in North Ames, Edwards, and Brookside Neighborhoods")  +
  xlab("Square Footage of Living Area") +
  ylab("House Sale Price") +
  scale_y_continuous(labels = comma)

# Without two outliers of 3,500+ sq ft
train_filtered_ranged = train %>% filter(Neighborhood == "NAmes" | Neighborhood == "Edwards" | Neighborhood == "BrkSide") %>% filter(GrLivArea <= 3500)
train_filtered_ranged2 = train_filtered_ranged %>% select(SalePrice, GrLivArea)
# Sales Prices' relation to square footage of the Living Area
## Create linear model of Response (SalePrice) to Explanatory Variables (GrLivArea)
fit_ranged = lm(SalePrice~GrLivArea, data=train_filtered_ranged)
## Find the overall Summary and Confidence Interval of our Linear Model
# Option 1 for auto-generating summary statistics -- PDF doesn't like, good for HTML quick referencing
tab_model(fit_ranged, show.se = T, show.stat = T, string.stat = "t-value", string.p = "p-value", string.se = "Std. Error", pred.labels = c("Intercept", "Sq. Ft. of Living Area"))
# Option 2 - Use for PDF
summary(fit_ranged)
confint(fit_ranged)
CV(fit_ranged)
cor(train_filtered_ranged2)

preds_filtered_ranged = predict(fit_ranged)
train_filtered_ranged2 %>% ggplot(aes(y = SalePrice, x = GrLivArea)) +
  geom_point() + geom_smooth(method = "lm", formula = y~x) +
  ggtitle("Linear Regression Model: Living Area vs. Sale Price", "Range Limitation (0 to 3,500 sqft)")  +
  xlab("Square Footage of Living Area") +
  ylab("House Sale Price") +
  scale_y_continuous(labels = comma)

```

## Step 2: Checking Assumptions
Assumptions:
- There is a normally distributed sub-population of responses for each value of the explanatory variable (Normalcy)
- The means of the sub-populations fall on a straight line function of the explanatory variable (Linear Relationship)
- The sub-population standard deviation are all equal (to $\sigma$) (Equivalent Variation)
- The selection of an observation from any of the sub-populations is independent of the selection of any other observation (Independence)
### Examining Residual Plots & Influential Points
```{r Initial Model Plots, echo=T}
resid_panel(fit_initial, plots=c("resid","qq","ls","index","cookd","lev"))
resid_panel(fit_ranged, plots=c("resid","qq","ls","index","cookd","lev"))
```
Generally speaking, our initial model demonstrates a medium positive linear association between a living room square footage and the sale price of a home in our three neighborhoods ($r^2=.342$, $adjr^2 = .341$).
## Step 3: Comparing Competing Models
```{r Transformations, echo=T}
# Create a new train set with log transformations w/ desired variables
train_log = train_filtered_ranged %>% as.data.frame(train_filtered_ranged$GrLivArea,train_filtered_ranged$SalePrice,train_filtered_ranged$Neighborhood)
train_log$lGrLivArea = log(train_log$GrLivArea)
train_log$lSalePrice = log(train_log$SalePrice)
```
### normal-log Model Analysis: 
$\hat{Sale Price} =  \hat{\beta_0} + \hat{\beta_1} (log(Living Area ft^2))$
```{r logGrLivArea Analysis, echo=T}
fit1 = lm(SalePrice~lGrLivArea, data=train_log)
# Option 1 for auto-generating summary statistics -- PDF doesn't like, good for HTML quick referencing
tab_model(fit1, show.se = T, show.stat = T, string.stat = "t-value", string.p = "p-value", string.se = "Std. Error", pred.labels = c("Intercept", "Sq. Ft. of Living Area"))
summary(fit1)
confint(fit1)
CV(fit1)

train_filtered_log1 = train_log %>% filter(Neighborhood == "NAmes" | Neighborhood == "Edwards" | Neighborhood == "BrkSide") %>% select(SalePrice, lGrLivArea)
cor(train_filtered_log1)

resid_panel(fit1, plots=c("resid","qq","ls","index","cookd","lev"))
preds1 = predict(fit1)
train_log %>% ggplot(aes(y = SalePrice, x = lGrLivArea)) + geom_point() + geom_smooth(method = "lm",formula = y~x)
train_log %>% ggplot(aes(y = SalePrice, x = lGrLivArea)) + geom_point() + geom_line(data = train_log, aes( x = lGrLivArea, y = preds1))
```
### log-normal Model Analysis:
Model: $log(\hat{Sale Price}) =  \hat{\beta_0} + \hat{\beta_1} (Living Area ft^2)$
```{r logSalePrice Analysis, echo=T}
fit2 = lm(lSalePrice~GrLivArea, data=train_log)
# Option 1 for auto-generating summary statistics -- PDF doesn't like, good for HTML quick referencing
tab_model(fit2, show.se = T, show.stat = T, string.stat = "t-value", string.p = "p-value", string.se = "Std. Error", pred.labels = c("Intercept", "Sq. Ft. of Living Area"))
summary(fit2)
confint(fit2)
CV(fit2)

train_filtered_log2 = train_log %>% filter(Neighborhood == "NAmes" | Neighborhood == "Edwards" | Neighborhood == "BrkSide") %>% select(lSalePrice, GrLivArea)
cor(train_filtered_log2)

resid_panel(fit2, plots=c("resid","qq","ls","index","cookd","lev"))
preds2 = predict(fit2)
train_log %>% ggplot(aes(y = lSalePrice, x = GrLivArea)) + geom_point() + geom_smooth(method = "lm",formula = y~x)
train_log %>% ggplot(aes(y = lSalePrice, x = GrLivArea)) + geom_point() + geom_line(data = train_log, aes( x = GrLivArea, y = preds2))
```
### log-log Model
```{r log-log Model Analysis, echo=T}
fit3 = lm(lSalePrice~lGrLivArea, data=train_log)
# Option 1 for auto-generating summary statistics -- PDF doesn't like, good for HTML quick referencing
tab_model(fit3, show.se = T, show.stat = T, string.stat = "t-value", string.p = "p-value", string.se = "Std. Error")
summary(fit3)
confint(fit3)
CV(fit3)

train_filtered_log3 = train_log %>% filter(Neighborhood == "NAmes" | Neighborhood == "Edwards" | Neighborhood == "BrkSide") %>% select(lSalePrice, lGrLivArea)
cor(train_filtered_log3)

resid_panel(fit3, plots=c("resid","qq","ls","index","cookd","lev"))
preds3 = predict(fit3)
train_log %>% ggplot(aes(y = lSalePrice, x = lGrLivArea)) + geom_point() + geom_smooth(method = "lm",formula = y~x)
```

### log-log Model with Neighborhood
```{r Neighborhood Model Analysis, echo=T}
fit4 = lm(lSalePrice~lGrLivArea + Neighborhood, data=train_log)
# Option 1 for auto-generating summary statistics -- PDF doesn't like, good for HTML quick referencing
tab_model(fit4, show.se = T, show.stat = T, show.df = T, string.stat = "t-value", string.p = "p-value", string.se = "Std. Error")
summary(fit4)
confint(fit4)
CV(fit4)

train_filtered_log4 = train_log %>% filter(Neighborhood == "NAmes" | Neighborhood == "Edwards" | Neighborhood == "BrkSide") %>% select(lSalePrice, lGrLivArea)
cor(train_filtered_log4)


resid_panel(fit4, plots=c("resid","qq","ls","index","cookd","lev"))
preds4 = predict(fit4)
train_log %>% ggplot(aes(y = lSalePrice, x = lGrLivArea)) + geom_point() + geom_smooth(method = "lm",formula = y~x)
train_log %>% ggplot(aes(y = lSalePrice, x = lGrLivArea, color=Neighborhood)) + geom_point() + geom_smooth(method = "lm",formula = y~x)
train_log %>% ggplot(aes(y = lSalePrice, x = lGrLivArea, color=Neighborhood)) + geom_point() + geom_line(data = train_log, aes(group=Neighborhood, x = lGrLivArea, y = preds4))
```

### log-log Model with Neighborhood*GrLivArea
```{r Neighborhood Model Analysis, echo=T}
fit5 = lm(lSalePrice~lGrLivArea + Neighborhood + Neighborhood:lGrLivArea, data=train_log)
# Option 1 for auto-generating summary statistics -- PDF doesn't like, good for HTML quick referencing
tab_model(fit5, show.se = T, show.stat = T, show.df = T, string.stat = "t-value", string.p = "p-value", string.se = "Std. Error")
summary(fit5)
confint(fit5)
CV(fit5)

train_filtered_log5 = train_log %>% filter(Neighborhood == "NAmes" | Neighborhood == "Edwards" | Neighborhood == "BrkSide") %>% select(lSalePrice, lGrLivArea)
cor(train_filtered_log4)


resid_panel(fit5, plots=c("resid","qq","ls","index","cookd","lev"))
preds4 = predict(fit5)
train_log %>% ggplot(aes(y = lSalePrice, x = lGrLivArea)) + geom_point() + geom_smooth(method = "lm",formula = y~x)
train_log %>% ggplot(aes(y = lSalePrice, x = lGrLivArea, color=Neighborhood)) + geom_point() + geom_smooth(method = "lm",formula = y~x)
train_log %>% ggplot(aes(y = lSalePrice, x = lGrLivArea, color=Neighborhood)) + geom_point() + geom_line(data = train_log, aes(group=Neighborhood, x = lGrLivArea, y = preds4))
```
